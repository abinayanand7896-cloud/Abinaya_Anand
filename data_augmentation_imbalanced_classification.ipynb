{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYy+8b1wWSkSnQc5HbJHvq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abinayanand7896-cloud/Abinaya_Anand/blob/main/data_augmentation_imbalanced_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Importing Required Libraries**"
      ],
      "metadata": {
        "id": "tRRgwRWXFfan"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYTWX8fuFK1Y",
        "outputId": "cb151865-6d25-49ed-9871-af3d9d877d25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import defaultdict\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    roc_auc_score,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        ")\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "\n",
        "# CTGAN\n",
        "try:\n",
        "    from ctgan import CTGAN\n",
        "except ImportError:\n",
        "    print(\"Installing CTGAN...\")\n",
        "    !pip install ctgan\n",
        "    from ctgan import CTGAN\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "\n",
        "print(\"All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Preparing and loading datasets**"
      ],
      "metadata": {
        "id": "lV8tmCY-HKEH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.1. Dataset 1: Breast Cancer**"
      ],
      "metadata": {
        "id": "vwyc8_VHHdUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Breast Cancer dataset\n",
        "print(\" LOADING DATASET 1: BREAST CANCER\")\n",
        "\n",
        "df_breast = pd.read_csv('/content/Breast_Cancer.csv')\n",
        "\n",
        "print(f\"\\nDataset Shape: {df_breast.shape}\")\n",
        "print(f\"\\nColumns: {df_breast.columns.tolist()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(df_breast.head())\n",
        "print(f\"\\nMissing values:\\n{df_breast.isnull().sum().sum()} total\")\n",
        "\n",
        "# Prepare features and target\n",
        "df_breast_clean = df_breast.copy()\n",
        "\n",
        "# Using 'Status' as target: Alive (0) vs Dead (1)\n",
        "df_breast_clean['target'] = (df_breast_clean['Status'] == 'Dead').astype(int)\n",
        "\n",
        "print(f\"\\nTarget distribution (Status):\")\n",
        "print(df_breast_clean['target'].value_counts())\n",
        "print(f\"Original imbalance ratio: 1:{df_breast_clean['target'].value_counts()[0] / df_breast_clean['target'].value_counts()[1]:.2f}\")\n",
        "\n",
        "# Drop target column from features\n",
        "X_breast = df_breast_clean.drop(['Status', 'target'], axis=1)\n",
        "y_breast = df_breast_clean['target']\n",
        "\n",
        "# Encode categorical variables\n",
        "categorical_cols = X_breast.select_dtypes(include=['object']).columns\n",
        "print(f\"\\nCategorical columns: {list(categorical_cols)}\")\n",
        "\n",
        "X_breast_encoded = pd.get_dummies(X_breast, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "print(f\"\\n Breast Cancer Dataset\")\n",
        "print(f\"  Features: {X_breast_encoded.shape[1]}\")\n",
        "print(f\"  Samples: {len(y_breast)}\")\n",
        "print(f\"  Positive class (Dead): {(y_breast == 1).sum()}\")\n",
        "print(f\"  Negative class (Alive): {(y_breast == 0).sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G99fuRBsHKdk",
        "outputId": "a193bf91-adf3-4380-afd8-40c5b0511f5e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " LOADING DATASET 1: BREAST CANCER\n",
            "\n",
            "Dataset Shape: (4024, 16)\n",
            "\n",
            "Columns: ['Age', 'Race', 'Marital Status', 'T Stage ', 'N Stage', '6th Stage', 'differentiate', 'Grade', 'A Stage', 'Tumor Size', 'Estrogen Status', 'Progesterone Status', 'Regional Node Examined', 'Reginol Node Positive', 'Survival Months', 'Status']\n",
            "\n",
            "First few rows:\n",
            "   Age   Race Marital Status T Stage  N Stage 6th Stage  \\\n",
            "0   68  White        Married       T1      N1       IIA   \n",
            "1   50  White        Married       T2      N2      IIIA   \n",
            "2   58  White       Divorced       T3      N3      IIIC   \n",
            "3   58  White        Married       T1      N1       IIA   \n",
            "4   47  White        Married       T2      N1       IIB   \n",
            "\n",
            "               differentiate Grade   A Stage  Tumor Size Estrogen Status  \\\n",
            "0      Poorly differentiated     3  Regional           4        Positive   \n",
            "1  Moderately differentiated     2  Regional          35        Positive   \n",
            "2  Moderately differentiated     2  Regional          63        Positive   \n",
            "3      Poorly differentiated     3  Regional          18        Positive   \n",
            "4      Poorly differentiated     3  Regional          41        Positive   \n",
            "\n",
            "  Progesterone Status  Regional Node Examined  Reginol Node Positive  \\\n",
            "0            Positive                      24                      1   \n",
            "1            Positive                      14                      5   \n",
            "2            Positive                      14                      7   \n",
            "3            Positive                       2                      1   \n",
            "4            Positive                       3                      1   \n",
            "\n",
            "   Survival Months Status  \n",
            "0               60  Alive  \n",
            "1               62  Alive  \n",
            "2               75  Alive  \n",
            "3               84  Alive  \n",
            "4               50  Alive  \n",
            "\n",
            "Missing values:\n",
            "0 total\n",
            "\n",
            "Target distribution (Status):\n",
            "target\n",
            "0    3408\n",
            "1     616\n",
            "Name: count, dtype: int64\n",
            "Original imbalance ratio: 1:5.53\n",
            "\n",
            "Categorical columns: ['Race', 'Marital Status', 'T Stage ', 'N Stage', '6th Stage', 'differentiate', 'Grade', 'A Stage', 'Estrogen Status', 'Progesterone Status']\n",
            "\n",
            " Breast Cancer Dataset\n",
            "  Features: 29\n",
            "  Samples: 4024\n",
            "  Positive class (Dead): 616\n",
            "  Negative class (Alive): 3408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.2. Dataset 2: Credit card fraud**"
      ],
      "metadata": {
        "id": "WFJTbvAgKt1W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7",
        "outputId": "586fc1f0-595d-4fac-a037-3badac43dd0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " LOADING DATASET 2: CREDIT CARD FRAUD\n",
            "\n",
            "Dataset Shape: (284807, 31)\n",
            "\n",
            "Columns: ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class']\n",
            "\n",
            "First few rows:\n",
            "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
            "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
            "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
            "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
            "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
            "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
            "\n",
            "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
            "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
            "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
            "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
            "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
            "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
            "\n",
            "        V26       V27       V28  Amount  Class  \n",
            "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
            "1  0.125895 -0.008983  0.014724    2.69      0  \n",
            "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
            "3 -0.221929  0.062723  0.061458  123.50      0  \n",
            "4  0.502292  0.219422  0.215153   69.99      0  \n",
            "\n",
            "[5 rows x 31 columns]\n",
            "\n",
            "Missing values:\n",
            "0 total\n",
            "\n",
            "Target distribution (Class):\n",
            "Class\n",
            "0    284315\n",
            "1       492\n",
            "Name: count, dtype: int64\n",
            "Original imbalance ratio: 1:577.88\n",
            "\n",
            "No categorical columns found - all features are numeric\n",
            "\n",
            " Credit Card Dataset\n",
            "  Features: 30\n",
            "  Samples: 284807\n",
            "  Positive class (Fraud): 492\n",
            "  Negative class (Legitimate): 284315\n"
          ]
        }
      ],
      "source": [
        "# Load Credit Card Fraud dataset\n",
        "print(\" LOADING DATASET 2: CREDIT CARD FRAUD\")\n",
        "\n",
        "df_credit = pd.read_csv('/content/creditcard.csv')\n",
        "\n",
        "print(f\"\\nDataset Shape: {df_credit.shape}\")\n",
        "print(f\"\\nColumns: {df_credit.columns.tolist()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "print(df_credit.head())\n",
        "print(f\"\\nMissing values:\\n{df_credit.isnull().sum().sum()} total\")\n",
        "\n",
        "# Prepare features and target\n",
        "# Assuming 'Class' column is the target (0 = legitimate, 1 = fraud)\n",
        "if 'Class' in df_credit.columns:\n",
        "    target_col = 'Class'\n",
        "elif 'class' in df_credit.columns:\n",
        "    target_col = 'class'\n",
        "else:\n",
        "    # If Class column doesn't exist, use the last column\n",
        "    target_col = df_credit.columns[-1]\n",
        "    print(f\"\\nNote: Using '{target_col}' as target column\")\n",
        "\n",
        "X_credit = df_credit.drop(target_col, axis=1)\n",
        "y_credit = df_credit[target_col]\n",
        "\n",
        "print(f\"\\nTarget distribution ({target_col}):\")\n",
        "print(y_credit.value_counts())\n",
        "if len(y_credit.value_counts()) > 1:\n",
        "    print(f\"Original imbalance ratio: 1:{y_credit.value_counts()[0] / y_credit.value_counts()[1]:.2f}\")\n",
        "\n",
        "# Handle categorical columns if any\n",
        "categorical_cols = X_credit.select_dtypes(include=['object']).columns\n",
        "if len(categorical_cols) > 0:\n",
        "    print(f\"\\nCategorical columns: {list(categorical_cols)}\")\n",
        "    X_credit_encoded = pd.get_dummies(X_credit, columns=categorical_cols, drop_first=True)\n",
        "else:\n",
        "    X_credit_encoded = X_credit.copy()\n",
        "    print(\"\\nNo categorical columns found - all features are numeric\")\n",
        "\n",
        "print(f\"\\n Credit Card Dataset\")\n",
        "print(f\"  Features: {X_credit_encoded.shape[1]}\")\n",
        "print(f\"  Samples: {len(y_credit)}\")\n",
        "print(f\"  Positive class (Fraud): {(y_credit == 1).sum()}\")\n",
        "print(f\"  Negative class (Legitimate): {(y_credit == 0).sum()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Helper Functions**"
      ],
      "metadata": {
        "id": "0xC4GBjIVx9O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_imbalanced_dataset(X, y, ratio, minority_class=1, random_state=42):\n",
        "    \"\"\"\n",
        "    Create an imbalanced dataset with specified ratio.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    X : array-like\n",
        "        Feature matrix\n",
        "    y : array-like\n",
        "        Target vector\n",
        "    ratio : int\n",
        "        Imbalance ratio (e.g., 10 for 1:10, 100 for 1:100)\n",
        "    minority_class : int\n",
        "        Label of minority class (default=1)\n",
        "    random_state : int\n",
        "        Random seed\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    X_imb, y_imb : Imbalanced dataset\n",
        "    \"\"\"\n",
        "    np.random.seed(random_state)\n",
        "\n",
        "    # Separate majority and minority classes\n",
        "    minority_mask = y == minority_class\n",
        "    majority_mask = ~minority_mask\n",
        "\n",
        "    X_minority = X[minority_mask]\n",
        "    y_minority = y[minority_mask]\n",
        "\n",
        "    X_majority = X[majority_mask]\n",
        "    y_majority = y[majority_mask]\n",
        "\n",
        "    # Calculate desired number of minority samples\n",
        "    n_minority_desired = max(50, int(len(y_minority) * 0.3))  # At least 50 samples\n",
        "    n_majority_desired = n_minority_desired * ratio\n",
        "\n",
        "    # Sample minority class\n",
        "    if len(y_minority) > n_minority_desired:\n",
        "        minority_indices = np.random.choice(\n",
        "            len(y_minority),\n",
        "            size=n_minority_desired,\n",
        "            replace=False\n",
        "        )\n",
        "    else:\n",
        "        minority_indices = np.arange(len(y_minority))\n",
        "        n_minority_desired = len(y_minority)\n",
        "        n_majority_desired = n_minority_desired * ratio\n",
        "\n",
        "    # Sample majority class\n",
        "    if len(y_majority) > n_majority_desired:\n",
        "        majority_indices = np.random.choice(\n",
        "            len(y_majority),\n",
        "            size=n_majority_desired,\n",
        "            replace=False\n",
        "        )\n",
        "    else:\n",
        "        # If not enough majority samples, sample with replacement\n",
        "        majority_indices = np.random.choice(\n",
        "            len(y_majority),\n",
        "            size=n_majority_desired,\n",
        "            replace=True\n",
        "        )\n",
        "\n",
        "    # Combine minority and majority\n",
        "    if isinstance(X, pd.DataFrame):\n",
        "        X_minority_sampled = X_minority.iloc[minority_indices]\n",
        "        y_minority_sampled = y_minority.iloc[minority_indices]\n",
        "\n",
        "        X_majority_sampled = X_majority.iloc[majority_indices]\n",
        "        y_majority_sampled = y_majority.iloc[majority_indices]\n",
        "\n",
        "        X_imb = pd.concat([X_minority_sampled, X_majority_sampled], axis=0)\n",
        "        y_imb = pd.concat([y_minority_sampled, y_majority_sampled], axis=0)\n",
        "    else:\n",
        "        X_minority_sampled = X_minority[minority_indices]\n",
        "        y_minority_sampled = y_minority[minority_indices]\n",
        "\n",
        "        X_majority_sampled = X_majority[majority_indices]\n",
        "        y_majority_sampled = y_majority[majority_indices]\n",
        "\n",
        "        X_imb = np.vstack([X_minority_sampled, X_majority_sampled])\n",
        "        y_imb = np.concatenate([y_minority_sampled, y_majority_sampled])\n",
        "\n",
        "    # Shuffle\n",
        "    shuffle_idx = np.random.permutation(len(y_imb))\n",
        "    if isinstance(X_imb, pd.DataFrame):\n",
        "        X_imb = X_imb.iloc[shuffle_idx].reset_index(drop=True)\n",
        "        y_imb = y_imb.iloc[shuffle_idx].reset_index(drop=True)\n",
        "    else:\n",
        "        X_imb = X_imb[shuffle_idx]\n",
        "        y_imb = y_imb[shuffle_idx]\n",
        "\n",
        "    actual_ratio = (y_imb == 0).sum() / max((y_imb == 1).sum(), 1)\n",
        "    print(f\"Created dataset with ratio 1:{actual_ratio:.2f}\")\n",
        "    print(f\"Minority class: {(y_imb == 1).sum()} samples\")\n",
        "    print(f\"Majority class: {(y_imb == 0).sum()} samples\")\n",
        "    print(f\"Total samples: {len(y_imb)}\")\n",
        "\n",
        "    return X_imb, y_imb"
      ],
      "metadata": {
        "id": "GsEIGY0OWBrb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_train, y_train, X_test, y_test, model_name=\"Model\"):\n",
        "    \"\"\"\n",
        "    Train and evaluate a model, returning comprehensive metrics.\n",
        "    \"\"\"\n",
        "    # Train\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else y_pred\n",
        "\n",
        "    # Calculate metrics\n",
        "    metrics = {\n",
        "        'model': model_name,\n",
        "        'precision': precision_score(y_test, y_pred, zero_division=0),\n",
        "        'recall': recall_score(y_test, y_pred, zero_division=0),\n",
        "        'f1': f1_score(y_test, y_pred, zero_division=0),\n",
        "        'auc_roc': roc_auc_score(y_test, y_prob) if len(np.unique(y_test)) > 1 else 0.0\n",
        "    }\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def print_metrics(metrics_dict):\n",
        "    \"\"\"\n",
        "    Print metrics in a formatted table.\n",
        "    \"\"\"\n",
        "    df_metrics = pd.DataFrame(metrics_dict)\n",
        "    print(df_metrics.to_string(index=False))\n",
        "    return df_metrics"
      ],
      "metadata": {
        "id": "DdfPMiNaauBZ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Main Experiment**"
      ],
      "metadata": {
        "id": "AL7PgLIIatj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(X, y, ratio, variation_params, experiment_name, dataset_name):\n",
        "    \"\"\"\n",
        "    Run complete experiment for a given imbalance ratio with 5 variations.\n",
        "    \"\"\"\n",
        "    print(\"=\"*100)\n",
        "    print(f\" {experiment_name} | {dataset_name}\")\n",
        "    print(\"=\"*100)\n",
        "\n",
        "    # Create imbalanced dataset\n",
        "    print(f\"\\n Creating 1:{ratio} imbalanced dataset...\\n\")\n",
        "    X_imb, y_imb = create_imbalanced_dataset(X, y, ratio=ratio, random_state=RANDOM_STATE)\n",
        "\n",
        "    # Split into train and test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_imb, y_imb, test_size=0.3, random_state=RANDOM_STATE, stratify=y_imb\n",
        "    )\n",
        "\n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    print(f\"\\nTrain set: {X_train_scaled.shape}\")\n",
        "    print(f\"Test set: {X_test_scaled.shape}\")\n",
        "    print(f\"Train class distribution: {np.bincount(y_train)}\")\n",
        "    print(f\"Test class distribution: {np.bincount(y_test)}\")\n",
        "\n",
        "    # Store all results\n",
        "    all_results = []\n",
        "\n",
        "    # Run 5 variations\n",
        "    for var_idx, params in enumerate(variation_params, 1):\n",
        "        print(\"\\n\" + \"=\"*100)\n",
        "        print(f\"ðŸ”¬ VARIATION {var_idx}/{len(variation_params)}: {params['name']}\")\n",
        "        print(\"=\"*100)\n",
        "        print(f\"Parameters: SMOTE_k={params['smote_k']}, ADASYN_k={params['adasyn_k']}, CTGAN_epochs={params['ctgan_epochs']}\")\n",
        "\n",
        "        variation_results = []\n",
        "\n",
        "        # ------------------------\n",
        "        # 1. BASELINE (No augmentation)\n",
        "        # ------------------------\n",
        "        print(\"\\n[1/4] Running BASELINE...\")\n",
        "        for clf_name, clf in params['classifiers'].items():\n",
        "            metrics = evaluate_model(\n",
        "                clf, X_train_scaled, y_train, X_test_scaled, y_test,\n",
        "                model_name=f\"Baseline-{clf_name}\"\n",
        "            )\n",
        "            metrics['technique'] = 'Baseline'\n",
        "            metrics['variation'] = var_idx\n",
        "            variation_results.append(metrics)\n",
        "\n",
        "        # ------------------------\n",
        "        # 2. SMOTE\n",
        "        # ------------------------\n",
        "        print(\"\\n[2/4] Running SMOTE...\")\n",
        "        try:\n",
        "            # Adjust k_neighbors if needed\n",
        "            k_neighbors = min(params['smote_k'], (y_train == 1).sum() - 1)\n",
        "            if k_neighbors < 1:\n",
        "                k_neighbors = 1\n",
        "\n",
        "            smote = SMOTE(\n",
        "                k_neighbors=k_neighbors,\n",
        "                random_state=RANDOM_STATE\n",
        "            )\n",
        "            X_smote, y_smote = smote.fit_resample(X_train_scaled, y_train)\n",
        "            print(f\"SMOTE generated: {X_smote.shape[0]} samples (k_neighbors={k_neighbors})\")\n",
        "\n",
        "            for clf_name, clf in params['classifiers'].items():\n",
        "                metrics = evaluate_model(\n",
        "                    clf, X_smote, y_smote, X_test_scaled, y_test,\n",
        "                    model_name=f\"SMOTE-{clf_name}\"\n",
        "                )\n",
        "                metrics['technique'] = 'SMOTE'\n",
        "                metrics['variation'] = var_idx\n",
        "                variation_results.append(metrics)\n",
        "        except Exception as e:\n",
        "            print(f\"SMOTE failed: {e}\")\n",
        "\n",
        "        # ------------------------\n",
        "        # 3. ADASYN\n",
        "        # ------------------------\n",
        "        print(\"\\n[3/4] Running ADASYN...\")\n",
        "        try:\n",
        "            # Adjust n_neighbors if needed\n",
        "            n_neighbors = min(params['adasyn_k'], (y_train == 1).sum() - 1)\n",
        "            if n_neighbors < 1:\n",
        "                n_neighbors = 1\n",
        "\n",
        "            adasyn = ADASYN(\n",
        "                n_neighbors=n_neighbors,\n",
        "                random_state=RANDOM_STATE\n",
        "            )\n",
        "            X_adasyn, y_adasyn = adasyn.fit_resample(X_train_scaled, y_train)\n",
        "            print(f\"ADASYN generated: {X_adasyn.shape[0]} samples (n_neighbors={n_neighbors})\")\n",
        "\n",
        "            for clf_name, clf in params['classifiers'].items():\n",
        "                metrics = evaluate_model(\n",
        "                    clf, X_adasyn, y_adasyn, X_test_scaled, y_test,\n",
        "                    model_name=f\"ADASYN-{clf_name}\"\n",
        "                )\n",
        "                metrics['technique'] = 'ADASYN'\n",
        "                metrics['variation'] = var_idx\n",
        "                variation_results.append(metrics)\n",
        "        except Exception as e:\n",
        "            print(f\"ADASYN failed: {e}\")\n",
        "\n",
        "        # ------------------------\n",
        "        # 4. CTGAN\n",
        "        # ------------------------\n",
        "        print(\"\\n[4/4] Running CTGAN...\")\n",
        "        try:\n",
        "            # Prepare data for CTGAN (needs original un-scaled data)\n",
        "            train_df = X_train.copy()\n",
        "            if isinstance(train_df, np.ndarray):\n",
        "                train_df = pd.DataFrame(train_df)\n",
        "            train_df['target'] = y_train.values if hasattr(y_train, 'values') else y_train\n",
        "\n",
        "            minority_data = train_df[train_df['target'] == 1].drop('target', axis=1)\n",
        "\n",
        "            if len(minority_data) > 0:\n",
        "                # Train CTGAN\n",
        "                ctgan = CTGAN(epochs=params['ctgan_epochs'], verbose=False)\n",
        "                ctgan.fit(minority_data, discrete_columns=[])\n",
        "\n",
        "                # Generate synthetic samples\n",
        "                n_majority = (y_train == 0).sum()\n",
        "                n_minority = (y_train == 1).sum()\n",
        "                n_synthetic = n_majority - n_minority\n",
        "\n",
        "                if n_synthetic > 0:\n",
        "                    synthetic_data = ctgan.sample(n_synthetic)\n",
        "\n",
        "                    # Combine original + synthetic\n",
        "                    X_ctgan = pd.concat([\n",
        "                        train_df.drop('target', axis=1),\n",
        "                        synthetic_data\n",
        "                    ], ignore_index=True)\n",
        "\n",
        "                    y_ctgan = np.concatenate([\n",
        "                        y_train.values if hasattr(y_train, 'values') else y_train,\n",
        "                        np.ones(n_synthetic, dtype=int)\n",
        "                    ])\n",
        "\n",
        "                    # Scale\n",
        "                    X_ctgan_scaled = scaler.transform(X_ctgan)\n",
        "\n",
        "                    print(f\"CTGAN generated: {X_ctgan_scaled.shape[0]} samples\")\n",
        "\n",
        "                    for clf_name, clf in params['classifiers'].items():\n",
        "                        metrics = evaluate_model(\n",
        "                            clf, X_ctgan_scaled, y_ctgan, X_test_scaled, y_test,\n",
        "                            model_name=f\"CTGAN-{clf_name}\"\n",
        "                        )\n",
        "                        metrics['technique'] = 'CTGAN'\n",
        "                        metrics['variation'] = var_idx\n",
        "                        variation_results.append(metrics)\n",
        "                else:\n",
        "                    print(\"CTGAN skipped: Already balanced\")\n",
        "            else:\n",
        "                print(\"CTGAN skipped: No minority samples\")\n",
        "        except Exception as e:\n",
        "            print(f\"CTGAN failed: {e}\")\n",
        "\n",
        "        # Print variation results\n",
        "        print(f\"\\n Variation {var_idx} Results:\")\n",
        "        print(\"-\" * 100)\n",
        "        df_var = print_metrics(variation_results)\n",
        "\n",
        "        all_results.extend(variation_results)\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df_results = pd.DataFrame(all_results)\n",
        "    df_results['dataset'] = dataset_name\n",
        "\n",
        "    # Print summary\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(f\" {experiment_name} - {dataset_name} - SUMMARY\")\n",
        "    print(\"=\"*100)\n",
        "\n",
        "    if len(df_results) > 0:\n",
        "        summary = df_results.groupby('technique')[[ 'precision', 'recall', 'f1', 'auc_roc']].agg(['mean', 'std'])\n",
        "        print(summary)\n",
        "\n",
        "    return df_results"
      ],
      "metadata": {
        "id": "sUHZCPR5a0-O"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Defining 5 variations**"
      ],
      "metadata": {
        "id": "xLHMSvbqbUTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define 5 variations with different parameters\n",
        "variations = [\n",
        "    # Variation 1: Conservative sampling + Simple models\n",
        "    {\n",
        "        'name': 'Conservative-Simple',\n",
        "        'smote_k': 3,\n",
        "        'adasyn_k': 3,\n",
        "        'ctgan_epochs': 100,\n",
        "        'classifiers': {\n",
        "            'LogReg': LogisticRegression(max_iter=1000, random_state=RANDOM_STATE),\n",
        "            'RF': RandomForestClassifier(n_estimators=50, max_depth=5, random_state=RANDOM_STATE)\n",
        "        }\n",
        "    },\n",
        "\n",
        "    # Variation 2: Moderate sampling + Balanced models\n",
        "    {\n",
        "        'name': 'Moderate-Balanced',\n",
        "        'smote_k': 5,\n",
        "        'adasyn_k': 5,\n",
        "        'ctgan_epochs': 150,\n",
        "        'classifiers': {\n",
        "            'LogReg': LogisticRegression(max_iter=1000, C=0.5, random_state=RANDOM_STATE),\n",
        "            'XGBoost': XGBClassifier(n_estimators=100, max_depth=3, random_state=RANDOM_STATE, eval_metric='logloss')\n",
        "        }\n",
        "    },\n",
        "\n",
        "    # Variation 3: Aggressive sampling + Complex models\n",
        "    {\n",
        "        'name': 'Aggressive-Complex',\n",
        "        'smote_k': 7,\n",
        "        'adasyn_k': 7,\n",
        "        'ctgan_epochs': 200,\n",
        "        'classifiers': {\n",
        "            'RF': RandomForestClassifier(n_estimators=100, max_depth=10, random_state=RANDOM_STATE),\n",
        "            'XGBoost': XGBClassifier(n_estimators=150, max_depth=5, random_state=RANDOM_STATE, eval_metric='logloss')\n",
        "        }\n",
        "    },\n",
        "\n",
        "    # Variation 4: High neighbors + Deep models\n",
        "    {\n",
        "        'name': 'HighK-Deep',\n",
        "        'smote_k': 10,\n",
        "        'adasyn_k': 10,\n",
        "        'ctgan_epochs': 250,\n",
        "        'classifiers': {\n",
        "            'RF': RandomForestClassifier(n_estimators=200, max_depth=15, random_state=RANDOM_STATE),\n",
        "            'XGBoost': XGBClassifier(n_estimators=200, max_depth=7, learning_rate=0.1, random_state=RANDOM_STATE, eval_metric='logloss')\n",
        "        }\n",
        "    },\n",
        "\n",
        "    # Variation 5: Mixed approach with regularization\n",
        "    {\n",
        "        'name': 'Mixed-Regularized',\n",
        "        'smote_k': 5,\n",
        "        'adasyn_k': 8,\n",
        "        'ctgan_epochs': 300,\n",
        "        'classifiers': {\n",
        "            'LogReg': LogisticRegression(max_iter=1000, C=0.1, penalty='l2', random_state=RANDOM_STATE),\n",
        "            'RF': RandomForestClassifier(n_estimators=150, max_depth=8, min_samples_split=10, random_state=RANDOM_STATE)\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"5 Variations defined:\")\n",
        "for i, var in enumerate(variations, 1):\n",
        "    print(f\"  {i}. {var['name']}: SMOTE_k={var['smote_k']}, ADASYN_k={var['adasyn_k']}, CTGAN_epochs={var['ctgan_epochs']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZdjmLEsbZZ0",
        "outputId": "6a145baf-ddf5-4821-aa58-7f6d27a0ca2a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 Variations defined:\n",
            "  1. Conservative-Simple: SMOTE_k=3, ADASYN_k=3, CTGAN_epochs=100\n",
            "  2. Moderate-Balanced: SMOTE_k=5, ADASYN_k=5, CTGAN_epochs=150\n",
            "  3. Aggressive-Complex: SMOTE_k=7, ADASYN_k=7, CTGAN_epochs=200\n",
            "  4. HighK-Deep: SMOTE_k=10, ADASYN_k=10, CTGAN_epochs=250\n",
            "  5. Mixed-Regularized: SMOTE_k=5, ADASYN_k=8, CTGAN_epochs=300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Breast Cancer Dataset Experiments**"
      ],
      "metadata": {
        "id": "gDlQdnC7boN4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.1. Breast Cancer - Moderate Imbalance (1:10)**"
      ],
      "metadata": {
        "id": "cHYqqPgccD0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_breast_exp1 = run_experiment(\n",
        "    X=X_breast_encoded,\n",
        "    y=y_breast,\n",
        "    ratio=10,\n",
        "    variation_params=variations,\n",
        "    experiment_name=\"EXPERIMENT 1: Moderate Imbalance (1:10)\",\n",
        "    dataset_name=\"Breast Cancer\"\n",
        ")\n",
        "\n",
        "results_breast_exp1.to_csv('breast_cancer_exp1_1to10.csv', index=False)\n",
        "print(\"\\n Results saved to 'breast_cancer_exp1_1to10.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OSMrtiDcLv6",
        "outputId": "f738aadb-be3d-4216-cfd1-90516af9f351"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            " EXPERIMENT 1: Moderate Imbalance (1:10) | Breast Cancer\n",
            "====================================================================================================\n",
            "\n",
            " Creating 1:10 imbalanced dataset...\n",
            "\n",
            "Created dataset with ratio 1:10.00\n",
            "Minority class: 184 samples\n",
            "Majority class: 1840 samples\n",
            "Total samples: 2024\n",
            "\n",
            "Train set: (1416, 29)\n",
            "Test set: (608, 29)\n",
            "Train class distribution: [1287  129]\n",
            "Test class distribution: [553  55]\n",
            "\n",
            "====================================================================================================\n",
            "ðŸ”¬ VARIATION 1/5: Conservative-Simple\n",
            "====================================================================================================\n",
            "Parameters: SMOTE_k=3, ADASYN_k=3, CTGAN_epochs=100\n",
            "\n",
            "[1/4] Running BASELINE...\n",
            "\n",
            "[2/4] Running SMOTE...\n",
            "SMOTE generated: 2574 samples (k_neighbors=3)\n",
            "\n",
            "[3/4] Running ADASYN...\n",
            "ADASYN generated: 2612 samples (n_neighbors=3)\n",
            "\n",
            "[4/4] Running CTGAN...\n",
            "CTGAN generated: 2574 samples\n",
            "\n",
            " Variation 1 Results:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "          model  precision   recall       f1  auc_roc technique  variation\n",
            "Baseline-LogReg   0.787879 0.472727 0.590909 0.863094  Baseline          1\n",
            "    Baseline-RF   0.916667 0.200000 0.328358 0.870656  Baseline          1\n",
            "   SMOTE-LogReg   0.292857 0.745455 0.420513 0.864146     SMOTE          1\n",
            "       SMOTE-RF   0.480000 0.654545 0.553846 0.878218     SMOTE          1\n",
            "  ADASYN-LogReg   0.259259 0.763636 0.387097 0.859181    ADASYN          1\n",
            "      ADASYN-RF   0.486111 0.636364 0.551181 0.880092    ADASYN          1\n",
            "   CTGAN-LogReg   0.787879 0.472727 0.590909 0.865330     CTGAN          1\n",
            "       CTGAN-RF   0.923077 0.218182 0.352941 0.864195     CTGAN          1\n",
            "\n",
            "====================================================================================================\n",
            "ðŸ”¬ VARIATION 2/5: Moderate-Balanced\n",
            "====================================================================================================\n",
            "Parameters: SMOTE_k=5, ADASYN_k=5, CTGAN_epochs=150\n",
            "\n",
            "[1/4] Running BASELINE...\n",
            "\n",
            "[2/4] Running SMOTE...\n",
            "SMOTE generated: 2574 samples (k_neighbors=5)\n",
            "\n",
            "[3/4] Running ADASYN...\n",
            "ADASYN generated: 2564 samples (n_neighbors=5)\n",
            "\n",
            "[4/4] Running CTGAN...\n",
            "CTGAN generated: 2574 samples\n",
            "\n",
            " Variation 2 Results:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "           model  precision   recall       f1  auc_roc technique  variation\n",
            " Baseline-LogReg   0.806452 0.454545 0.581395 0.863850  Baseline          2\n",
            "Baseline-XGBoost   0.704545 0.563636 0.626263 0.860365  Baseline          2\n",
            "    SMOTE-LogReg   0.281690 0.727273 0.406091 0.861023     SMOTE          2\n",
            "   SMOTE-XGBoost   0.600000 0.600000 0.600000 0.866678     SMOTE          2\n",
            "   ADASYN-LogReg   0.266234 0.745455 0.392344 0.860759    ADASYN          2\n",
            "  ADASYN-XGBoost   0.566038 0.545455 0.555556 0.867171    ADASYN          2\n",
            "    CTGAN-LogReg   0.757576 0.454545 0.568182 0.867204     CTGAN          2\n",
            "   CTGAN-XGBoost   0.756098 0.563636 0.645833 0.874503     CTGAN          2\n",
            "\n",
            "====================================================================================================\n",
            "ðŸ”¬ VARIATION 3/5: Aggressive-Complex\n",
            "====================================================================================================\n",
            "Parameters: SMOTE_k=7, ADASYN_k=7, CTGAN_epochs=200\n",
            "\n",
            "[1/4] Running BASELINE...\n",
            "\n",
            "[2/4] Running SMOTE...\n",
            "SMOTE generated: 2574 samples (k_neighbors=7)\n",
            "\n",
            "[3/4] Running ADASYN...\n",
            "ADASYN generated: 2562 samples (n_neighbors=7)\n",
            "\n",
            "[4/4] Running CTGAN...\n",
            "CTGAN generated: 2574 samples\n",
            "\n",
            " Variation 3 Results:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "           model  precision   recall       f1  auc_roc technique  variation\n",
            "     Baseline-RF   0.740741 0.363636 0.487805 0.870755  Baseline          3\n",
            "Baseline-XGBoost   0.710526 0.490909 0.580645 0.856157  Baseline          3\n",
            "        SMOTE-RF   0.525424 0.563636 0.543860 0.879434     SMOTE          3\n",
            "   SMOTE-XGBoost   0.574074 0.563636 0.568807 0.871050     SMOTE          3\n",
            "       ADASYN-RF   0.596154 0.563636 0.579439 0.875390    ADASYN          3\n",
            "  ADASYN-XGBoost   0.612245 0.545455 0.576923 0.870196    ADASYN          3\n",
            "        CTGAN-RF   0.814815 0.400000 0.536585 0.865001     CTGAN          3\n",
            "   CTGAN-XGBoost   0.682927 0.509091 0.583333 0.854545     CTGAN          3\n",
            "\n",
            "====================================================================================================\n",
            "ðŸ”¬ VARIATION 4/5: HighK-Deep\n",
            "====================================================================================================\n",
            "Parameters: SMOTE_k=10, ADASYN_k=10, CTGAN_epochs=250\n",
            "\n",
            "[1/4] Running BASELINE...\n",
            "\n",
            "[2/4] Running SMOTE...\n",
            "SMOTE generated: 2574 samples (k_neighbors=10)\n",
            "\n",
            "[3/4] Running ADASYN...\n",
            "ADASYN generated: 2602 samples (n_neighbors=10)\n",
            "\n",
            "[4/4] Running CTGAN...\n",
            "CTGAN generated: 2574 samples\n",
            "\n",
            " Variation 4 Results:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "           model  precision   recall       f1  auc_roc technique  variation\n",
            "     Baseline-RF   0.758621 0.400000 0.523810 0.870081  Baseline          4\n",
            "Baseline-XGBoost   0.700000 0.509091 0.589474 0.855893  Baseline          4\n",
            "        SMOTE-RF   0.596154 0.563636 0.579439 0.866513     SMOTE          4\n",
            "   SMOTE-XGBoost   0.627451 0.581818 0.603774 0.861844     SMOTE          4\n",
            "       ADASYN-RF   0.566038 0.545455 0.555556 0.878974    ADASYN          4\n",
            "  ADASYN-XGBoost   0.629630 0.618182 0.623853 0.871577    ADASYN          4\n",
            "        CTGAN-RF   0.793103 0.418182 0.547619 0.855778     CTGAN          4\n",
            "   CTGAN-XGBoost   0.725000 0.527273 0.610526 0.857603     CTGAN          4\n",
            "\n",
            "====================================================================================================\n",
            "ðŸ”¬ VARIATION 5/5: Mixed-Regularized\n",
            "====================================================================================================\n",
            "Parameters: SMOTE_k=5, ADASYN_k=8, CTGAN_epochs=300\n",
            "\n",
            "[1/4] Running BASELINE...\n",
            "\n",
            "[2/4] Running SMOTE...\n",
            "SMOTE generated: 2574 samples (k_neighbors=5)\n",
            "\n",
            "[3/4] Running ADASYN...\n",
            "ADASYN generated: 2587 samples (n_neighbors=8)\n",
            "\n",
            "[4/4] Running CTGAN...\n",
            "CTGAN generated: 2574 samples\n",
            "\n",
            " Variation 5 Results:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "          model  precision   recall       f1  auc_roc technique  variation\n",
            "Baseline-LogReg   0.785714 0.400000 0.530120 0.866053  Baseline          5\n",
            "    Baseline-RF   0.807692 0.381818 0.518519 0.867335  Baseline          5\n",
            "   SMOTE-LogReg   0.285714 0.727273 0.410256 0.863653     SMOTE          5\n",
            "       SMOTE-RF   0.532258 0.600000 0.564103 0.887227     SMOTE          5\n",
            "  ADASYN-LogReg   0.269737 0.745455 0.396135 0.862469    ADASYN          5\n",
            "      ADASYN-RF   0.573770 0.636364 0.603448 0.882098    ADASYN          5\n",
            "   CTGAN-LogReg   0.758621 0.400000 0.523810 0.870196     CTGAN          5\n",
            "       CTGAN-RF   0.809524 0.309091 0.447368 0.863225     CTGAN          5\n",
            "\n",
            "====================================================================================================\n",
            " EXPERIMENT 1: Moderate Imbalance (1:10) - Breast Cancer - SUMMARY\n",
            "====================================================================================================\n",
            "          precision              recall                  f1            \\\n",
            "               mean       std      mean       std      mean       std   \n",
            "technique                                                               \n",
            "ADASYN     0.482522  0.154767  0.634545  0.088431  0.522153  0.092663   \n",
            "Baseline   0.771884  0.065404  0.423636  0.100705  0.535730  0.084328   \n",
            "CTGAN      0.780862  0.063910  0.427273  0.104006  0.540711  0.085204   \n",
            "SMOTE      0.479562  0.139591  0.632727  0.074622  0.525069  0.080037   \n",
            "\n",
            "            auc_roc            \n",
            "               mean       std  \n",
            "technique                      \n",
            "ADASYN     0.870791  0.008308  \n",
            "Baseline   0.864424  0.005595  \n",
            "CTGAN      0.863758  0.006322  \n",
            "SMOTE      0.869979  0.008815  \n",
            "\n",
            " Results saved to 'breast_cancer_exp1_1to10.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6.2. Breast Cancer - High Imbalance (1:100)**"
      ],
      "metadata": {
        "id": "komVlvAQb9wm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_breast_exp2 = run_experiment(\n",
        "    X=X_breast_encoded,\n",
        "    y=y_breast,\n",
        "    ratio=100,\n",
        "    variation_params=variations,\n",
        "    experiment_name=\"EXPERIMENT 2: High Imbalance (1:100)\",\n",
        "    dataset_name=\"Breast Cancer\"\n",
        ")\n",
        "\n",
        "results_breast_exp2.to_csv('breast_cancer_exp2_1to100.csv', index=False)\n",
        "print(\"\\nâœ“ Results saved to 'breast_cancer_exp2_1to100.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEvvuI0He0qw",
        "outputId": "5759223e-6745-48ff-e485-004ac24d591e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            " EXPERIMENT 2: High Imbalance (1:100) | Breast Cancer\n",
            "====================================================================================================\n",
            "\n",
            " Creating 1:100 imbalanced dataset...\n",
            "\n",
            "Created dataset with ratio 1:100.00\n",
            "Minority class: 184 samples\n",
            "Majority class: 18400 samples\n",
            "Total samples: 18584\n",
            "\n",
            "Train set: (13008, 29)\n",
            "Test set: (5576, 29)\n",
            "Train class distribution: [12879   129]\n",
            "Test class distribution: [5521   55]\n",
            "\n",
            "====================================================================================================\n",
            "ðŸ”¬ VARIATION 1/5: Conservative-Simple\n",
            "====================================================================================================\n",
            "Parameters: SMOTE_k=3, ADASYN_k=3, CTGAN_epochs=100\n",
            "\n",
            "[1/4] Running BASELINE...\n",
            "\n",
            "[2/4] Running SMOTE...\n",
            "SMOTE generated: 25758 samples (k_neighbors=3)\n",
            "\n",
            "[3/4] Running ADASYN...\n",
            "ADASYN generated: 25788 samples (n_neighbors=3)\n",
            "\n",
            "[4/4] Running CTGAN...\n",
            "CTGAN generated: 25758 samples\n",
            "\n",
            " Variation 1 Results:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "          model  precision   recall       f1  auc_roc technique  variation\n",
            "Baseline-LogReg   1.000000 0.127273 0.225806 0.838880  Baseline          1\n",
            "    Baseline-RF   1.000000 0.036364 0.070175 0.839726  Baseline          1\n",
            "   SMOTE-LogReg   0.040469 0.690909 0.076459 0.843141     SMOTE          1\n",
            "       SMOTE-RF   0.064315 0.563636 0.115456 0.803380     SMOTE          1\n",
            "  ADASYN-LogReg   0.039474 0.709091 0.074784 0.842624    ADASYN          1\n",
            "      ADASYN-RF   0.064386 0.581818 0.115942 0.799682    ADASYN          1\n",
            "   CTGAN-LogReg   1.000000 0.127273 0.225806 0.838149     CTGAN          1\n",
            "       CTGAN-RF   0.000000 0.000000 0.000000 0.828238     CTGAN          1\n",
            "\n",
            "====================================================================================================\n",
            "ðŸ”¬ VARIATION 2/5: Moderate-Balanced\n",
            "====================================================================================================\n",
            "Parameters: SMOTE_k=5, ADASYN_k=5, CTGAN_epochs=150\n",
            "\n",
            "[1/4] Running BASELINE...\n",
            "\n",
            "[2/4] Running SMOTE...\n",
            "SMOTE generated: 25758 samples (k_neighbors=5)\n",
            "\n",
            "[3/4] Running ADASYN...\n",
            "ADASYN generated: 25733 samples (n_neighbors=5)\n",
            "\n",
            "[4/4] Running CTGAN...\n",
            "CTGAN generated: 25758 samples\n",
            "\n",
            " Variation 2 Results:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "           model  precision   recall       f1  auc_roc technique  variation\n",
            " Baseline-LogReg   1.000000 0.127273 0.225806 0.839647  Baseline          2\n",
            "Baseline-XGBoost   0.894737 0.309091 0.459459 0.842558  Baseline          2\n",
            "    SMOTE-LogReg   0.041711 0.709091 0.078788 0.842084     SMOTE          2\n",
            "   SMOTE-XGBoost   0.355932 0.381818 0.368421 0.846335     SMOTE          2\n",
            "   ADASYN-LogReg   0.040541 0.709091 0.076696 0.843009    ADASYN          2\n",
            "  ADASYN-XGBoost   0.391304 0.327273 0.356436 0.849813    ADASYN          2\n",
            "    CTGAN-LogReg   1.000000 0.127273 0.225806 0.839137     CTGAN          2\n",
            "   CTGAN-XGBoost   0.900000 0.327273 0.480000 0.843444     CTGAN          2\n",
            "\n",
            "====================================================================================================\n",
            "ðŸ”¬ VARIATION 3/5: Aggressive-Complex\n",
            "====================================================================================================\n",
            "Parameters: SMOTE_k=7, ADASYN_k=7, CTGAN_epochs=200\n",
            "\n",
            "[1/4] Running BASELINE...\n",
            "\n",
            "[2/4] Running SMOTE...\n",
            "SMOTE generated: 25758 samples (k_neighbors=7)\n",
            "\n",
            "[3/4] Running ADASYN...\n",
            "ADASYN generated: 25758 samples (n_neighbors=7)\n",
            "\n",
            "[4/4] Running CTGAN...\n",
            "CTGAN generated: 25758 samples\n",
            "\n",
            " Variation 3 Results:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "           model  precision   recall       f1  auc_roc technique  variation\n",
            "     Baseline-RF   1.000000 0.163636 0.281250 0.881574  Baseline          3\n",
            "Baseline-XGBoost   0.900000 0.327273 0.480000 0.826115  Baseline          3\n",
            "        SMOTE-RF   0.244898 0.436364 0.313725 0.828582     SMOTE          3\n",
            "   SMOTE-XGBoost   1.000000 0.363636 0.533333 0.863085     SMOTE          3\n",
            "       ADASYN-RF   0.252632 0.436364 0.320000 0.828358    ADASYN          3\n",
            "  ADASYN-XGBoost   0.869565 0.363636 0.512821 0.862337    ADASYN          3\n",
            "        CTGAN-RF   1.000000 0.072727 0.135593 0.861767     CTGAN          3\n",
            "   CTGAN-XGBoost   0.909091 0.363636 0.519481 0.851809     CTGAN          3\n",
            "\n",
            "====================================================================================================\n",
            "ðŸ”¬ VARIATION 4/5: HighK-Deep\n",
            "====================================================================================================\n",
            "Parameters: SMOTE_k=10, ADASYN_k=10, CTGAN_epochs=250\n",
            "\n",
            "[1/4] Running BASELINE...\n",
            "\n",
            "[2/4] Running SMOTE...\n",
            "SMOTE generated: 25758 samples (k_neighbors=10)\n",
            "\n",
            "[3/4] Running ADASYN...\n",
            "ADASYN generated: 25756 samples (n_neighbors=10)\n",
            "\n",
            "[4/4] Running CTGAN...\n",
            "CTGAN generated: 25758 samples\n",
            "\n",
            " Variation 4 Results:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "           model  precision   recall       f1  auc_roc technique  variation\n",
            "     Baseline-RF   1.000000 0.218182 0.358209 0.914480  Baseline          4\n",
            "Baseline-XGBoost   0.904762 0.345455 0.500000 0.862535  Baseline          4\n",
            "        SMOTE-RF   0.800000 0.363636 0.500000 0.897130     SMOTE          4\n",
            "   SMOTE-XGBoost   0.913043 0.381818 0.538462 0.866161     SMOTE          4\n",
            "       ADASYN-RF   0.814815 0.400000 0.536585 0.900165    ADASYN          4\n",
            "  ADASYN-XGBoost   0.920000 0.418182 0.575000 0.862153    ADASYN          4\n",
            "        CTGAN-RF   1.000000 0.200000 0.333333 0.912307     CTGAN          4\n",
            "   CTGAN-XGBoost   0.909091 0.363636 0.519481 0.855342     CTGAN          4\n",
            "\n",
            "====================================================================================================\n",
            "ðŸ”¬ VARIATION 5/5: Mixed-Regularized\n",
            "====================================================================================================\n",
            "Parameters: SMOTE_k=5, ADASYN_k=8, CTGAN_epochs=300\n",
            "\n",
            "[1/4] Running BASELINE...\n",
            "\n",
            "[2/4] Running SMOTE...\n",
            "SMOTE generated: 25758 samples (k_neighbors=5)\n",
            "\n",
            "[3/4] Running ADASYN...\n",
            "ADASYN generated: 25801 samples (n_neighbors=8)\n",
            "\n",
            "[4/4] Running CTGAN...\n",
            "CTGAN generated: 25758 samples\n",
            "\n",
            " Variation 5 Results:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "          model  precision   recall       f1  auc_roc technique  variation\n",
            "Baseline-LogReg   1.000000 0.090909 0.166667 0.842258  Baseline          5\n",
            "    Baseline-RF   1.000000 0.072727 0.135593 0.852823  Baseline          5\n",
            "   SMOTE-LogReg   0.041622 0.709091 0.078629 0.842176     SMOTE          5\n",
            "       SMOTE-RF   0.126214 0.472727 0.199234 0.818633     SMOTE          5\n",
            "  ADASYN-LogReg   0.040082 0.709091 0.075875 0.840968    ADASYN          5\n",
            "      ADASYN-RF   0.126904 0.454545 0.198413 0.815109    ADASYN          5\n",
            "   CTGAN-LogReg   1.000000 0.109091 0.196721 0.844155     CTGAN          5\n",
            "       CTGAN-RF   1.000000 0.072727 0.135593 0.845680     CTGAN          5\n",
            "\n",
            "====================================================================================================\n",
            " EXPERIMENT 2: High Imbalance (1:100) - Breast Cancer - SUMMARY\n",
            "====================================================================================================\n",
            "          precision              recall                  f1            \\\n",
            "               mean       std      mean       std      mean       std   \n",
            "technique                                                               \n",
            "ADASYN     0.355970  0.371382  0.510909  0.151987  0.284255  0.203582   \n",
            "Baseline   0.969950  0.048443  0.181818  0.112080  0.290297  0.152484   \n",
            "CTGAN      0.871818  0.309520  0.176364  0.131405  0.277182  0.179624   \n",
            "SMOTE      0.362820  0.390029  0.507273  0.148070  0.280251  0.195618   \n",
            "\n",
            "            auc_roc            \n",
            "               mean       std  \n",
            "technique                      \n",
            "ADASYN     0.844422  0.027704  \n",
            "Baseline   0.854060  0.026198  \n",
            "CTGAN      0.852003  0.023190  \n",
            "SMOTE      0.845071  0.026270  \n",
            "\n",
            "âœ“ Results saved to 'breast_cancer_exp2_1to100.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Credit Card Dataset Experiments**"
      ],
      "metadata": {
        "id": "DLsVdy41faq2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.1. Credit Card - Moderate Imbalance (1:10)**"
      ],
      "metadata": {
        "id": "5YCviTwsfnmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_credit_exp1 = run_experiment(\n",
        "    X=X_credit_encoded,\n",
        "    y=y_credit,\n",
        "    ratio=10,\n",
        "    variation_params=variations,\n",
        "    experiment_name=\"EXPERIMENT 1: Moderate Imbalance (1:10)\",\n",
        "    dataset_name=\"Credit Card\"\n",
        ")\n",
        "\n",
        "results_credit_exp1.to_csv('credit_card_exp1_1to10.csv', index=False)\n",
        "print(\"\\nâœ“ Results saved to 'credit_card_exp1_1to10.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHbxf4HVffhG",
        "outputId": "5888ce11-9618-4172-dfa4-9eda285a48c9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            " EXPERIMENT 1: Moderate Imbalance (1:10) | Credit Card\n",
            "====================================================================================================\n",
            "\n",
            " Creating 1:10 imbalanced dataset...\n",
            "\n",
            "Created dataset with ratio 1:10.00\n",
            "Minority class: 147 samples\n",
            "Majority class: 1470 samples\n",
            "Total samples: 1617\n",
            "\n",
            "Train set: (1131, 30)\n",
            "Test set: (486, 30)\n",
            "Train class distribution: [1028  103]\n",
            "Test class distribution: [442  44]\n",
            "\n",
            "====================================================================================================\n",
            "ðŸ”¬ VARIATION 1/5: Conservative-Simple\n",
            "====================================================================================================\n",
            "Parameters: SMOTE_k=3, ADASYN_k=3, CTGAN_epochs=100\n",
            "\n",
            "[1/4] Running BASELINE...\n",
            "\n",
            "[2/4] Running SMOTE...\n",
            "SMOTE generated: 2056 samples (k_neighbors=3)\n",
            "\n",
            "[3/4] Running ADASYN...\n",
            "ADASYN generated: 2051 samples (n_neighbors=3)\n",
            "\n",
            "[4/4] Running CTGAN...\n",
            "CTGAN generated: 2056 samples\n",
            "\n",
            " Variation 1 Results:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "          model  precision   recall       f1  auc_roc technique  variation\n",
            "Baseline-LogReg   0.950000 0.863636 0.904762 0.955522  Baseline          1\n",
            "    Baseline-RF   1.000000 0.840909 0.913580 0.951897  Baseline          1\n",
            "   SMOTE-LogReg   0.816327 0.909091 0.860215 0.958402     SMOTE          1\n",
            "       SMOTE-RF   0.906977 0.886364 0.896552 0.948247     SMOTE          1\n",
            "  ADASYN-LogReg   0.602941 0.931818 0.732143 0.964469    ADASYN          1\n",
            "      ADASYN-RF   0.759259 0.931818 0.836735 0.962670    ADASYN          1\n",
            "   CTGAN-LogReg   0.950000 0.863636 0.904762 0.953620     CTGAN          1\n",
            "       CTGAN-RF   0.948718 0.840909 0.891566 0.943208     CTGAN          1\n",
            "\n",
            "====================================================================================================\n",
            "ðŸ”¬ VARIATION 2/5: Moderate-Balanced\n",
            "====================================================================================================\n",
            "Parameters: SMOTE_k=5, ADASYN_k=5, CTGAN_epochs=150\n",
            "\n",
            "[1/4] Running BASELINE...\n",
            "\n",
            "[2/4] Running SMOTE...\n",
            "SMOTE generated: 2056 samples (k_neighbors=5)\n",
            "\n",
            "[3/4] Running ADASYN...\n",
            "ADASYN generated: 2057 samples (n_neighbors=5)\n",
            "\n",
            "[4/4] Running CTGAN...\n",
            "CTGAN generated: 2056 samples\n",
            "\n",
            " Variation 2 Results:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "           model  precision   recall       f1  auc_roc technique  variation\n",
            " Baseline-LogReg   0.974359 0.863636 0.915663 0.955728  Baseline          2\n",
            "Baseline-XGBoost   1.000000 0.818182 0.900000 0.959070  Baseline          2\n",
            "    SMOTE-LogReg   0.795918 0.886364 0.838710 0.961641     SMOTE          2\n",
            "   SMOTE-XGBoost   0.926829 0.863636 0.894118 0.956602     SMOTE          2\n",
            "   ADASYN-LogReg   0.606061 0.909091 0.727273 0.959944    ADASYN          2\n",
            "  ADASYN-XGBoost   0.851064 0.909091 0.879121 0.959636    ADASYN          2\n",
            "    CTGAN-LogReg   0.975000 0.886364 0.928571 0.957476     CTGAN          2\n",
            "   CTGAN-XGBoost   1.000000 0.863636 0.926829 0.958350     CTGAN          2\n",
            "\n",
            "====================================================================================================\n",
            "ðŸ”¬ VARIATION 3/5: Aggressive-Complex\n",
            "====================================================================================================\n",
            "Parameters: SMOTE_k=7, ADASYN_k=7, CTGAN_epochs=200\n",
            "\n",
            "[1/4] Running BASELINE...\n",
            "\n",
            "[2/4] Running SMOTE...\n",
            "SMOTE generated: 2056 samples (k_neighbors=7)\n",
            "\n",
            "[3/4] Running ADASYN...\n",
            "ADASYN generated: 2055 samples (n_neighbors=7)\n",
            "\n",
            "[4/4] Running CTGAN...\n",
            "CTGAN generated: 2056 samples\n",
            "\n",
            " Variation 3 Results:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "           model  precision   recall       f1  auc_roc technique  variation\n",
            "     Baseline-RF   1.000000 0.818182 0.900000 0.959096  Baseline          3\n",
            "Baseline-XGBoost   1.000000 0.795455 0.886076 0.953209  Baseline          3\n",
            "        SMOTE-RF   0.930233 0.909091 0.919540 0.960304     SMOTE          3\n",
            "   SMOTE-XGBoost   0.926829 0.863636 0.894118 0.964881     SMOTE          3\n",
            "       ADASYN-RF   0.886364 0.886364 0.886364 0.962567    ADASYN          3\n",
            "  ADASYN-XGBoost   0.829787 0.886364 0.857143 0.957219    ADASYN          3\n",
            "        CTGAN-RF   1.000000 0.863636 0.926829 0.951872     CTGAN          3\n",
            "   CTGAN-XGBoost   0.950000 0.863636 0.904762 0.947141     CTGAN          3\n",
            "\n",
            "====================================================================================================\n",
            "ðŸ”¬ VARIATION 4/5: HighK-Deep\n",
            "====================================================================================================\n",
            "Parameters: SMOTE_k=10, ADASYN_k=10, CTGAN_epochs=250\n",
            "\n",
            "[1/4] Running BASELINE...\n",
            "\n",
            "[2/4] Running SMOTE...\n",
            "SMOTE generated: 2056 samples (k_neighbors=10)\n",
            "\n",
            "[3/4] Running ADASYN...\n",
            "ADASYN generated: 2057 samples (n_neighbors=10)\n",
            "\n",
            "[4/4] Running CTGAN...\n",
            "CTGAN generated: 2056 samples\n",
            "\n",
            " Variation 4 Results:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "           model  precision   recall       f1  auc_roc technique  variation\n",
            "     Baseline-RF   1.000000 0.818182 0.900000 0.956088  Baseline          4\n",
            "Baseline-XGBoost   1.000000 0.840909 0.913580 0.965498  Baseline          4\n",
            "        SMOTE-RF   0.975000 0.886364 0.928571 0.959559     SMOTE          4\n",
            "   SMOTE-XGBoost   0.925000 0.840909 0.880952 0.963801     SMOTE          4\n",
            "       ADASYN-RF   0.926829 0.863636 0.894118 0.969380    ADASYN          4\n",
            "  ADASYN-XGBoost   0.847826 0.886364 0.866667 0.961487    ADASYN          4\n",
            "        CTGAN-RF   0.926829 0.863636 0.894118 0.956936     CTGAN          4\n",
            "   CTGAN-XGBoost   1.000000 0.863636 0.926829 0.950021     CTGAN          4\n",
            "\n",
            "====================================================================================================\n",
            "ðŸ”¬ VARIATION 5/5: Mixed-Regularized\n",
            "====================================================================================================\n",
            "Parameters: SMOTE_k=5, ADASYN_k=8, CTGAN_epochs=300\n",
            "\n",
            "[1/4] Running BASELINE...\n",
            "\n",
            "[2/4] Running SMOTE...\n",
            "SMOTE generated: 2056 samples (k_neighbors=5)\n",
            "\n",
            "[3/4] Running ADASYN...\n",
            "ADASYN generated: 2058 samples (n_neighbors=8)\n",
            "\n",
            "[4/4] Running CTGAN...\n",
            "CTGAN generated: 2056 samples\n",
            "\n",
            " Variation 5 Results:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "          model  precision   recall       f1  auc_roc technique  variation\n",
            "Baseline-LogReg   1.000000 0.818182 0.900000 0.957168  Baseline          5\n",
            "    Baseline-RF   1.000000 0.818182 0.900000 0.954134  Baseline          5\n",
            "   SMOTE-LogReg   0.780000 0.886364 0.829787 0.961076     SMOTE          5\n",
            "       SMOTE-RF   0.926829 0.863636 0.894118 0.943747     SMOTE          5\n",
            "  ADASYN-LogReg   0.634921 0.909091 0.747664 0.955574    ADASYN          5\n",
            "      ADASYN-RF   0.909091 0.909091 0.909091 0.957991    ADASYN          5\n",
            "   CTGAN-LogReg   1.000000 0.818182 0.900000 0.953209     CTGAN          5\n",
            "       CTGAN-RF   0.974359 0.863636 0.915663 0.951974     CTGAN          5\n",
            "\n",
            "====================================================================================================\n",
            " EXPERIMENT 1: Moderate Imbalance (1:10) - Credit Card - SUMMARY\n",
            "====================================================================================================\n",
            "          precision              recall                  f1            \\\n",
            "               mean       std      mean       std      mean       std   \n",
            "technique                                                               \n",
            "ADASYN     0.785414  0.126691  0.902273  0.021561  0.833632  0.070600   \n",
            "Baseline   0.992436  0.016949  0.829545  0.022087  0.903366  0.008928   \n",
            "CTGAN      0.972491  0.027282  0.859091  0.017928  0.911993  0.014658   \n",
            "SMOTE      0.890994  0.067326  0.879545  0.021561  0.883668  0.032108   \n",
            "\n",
            "            auc_roc            \n",
            "               mean       std  \n",
            "technique                      \n",
            "ADASYN     0.961094  0.003992  \n",
            "Baseline   0.956741  0.003852  \n",
            "CTGAN      0.952381  0.004740  \n",
            "SMOTE      0.957826  0.006762  \n",
            "\n",
            "âœ“ Results saved to 'credit_card_exp1_1to10.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7.2. Credit Card - High Imbalance (1:100)**"
      ],
      "metadata": {
        "id": "PHPl5xkofrc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_credit_exp2 = run_experiment(\n",
        "    X=X_credit_encoded,\n",
        "    y=y_credit,\n",
        "    ratio=100,\n",
        "    variation_params=variations,\n",
        "    experiment_name=\"EXPERIMENT 2: High Imbalance (1:100)\",\n",
        "    dataset_name=\"Credit Card\"\n",
        ")\n",
        "\n",
        "results_credit_exp2.to_csv('credit_card_exp2_1to100.csv', index=False)\n",
        "print(\"\\nâœ“ Results saved to 'credit_card_exp2_1to100.csv'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJUv1cx8faEJ",
        "outputId": "468ffe85-f051-4da6-e7dc-0443a84c4133"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            " EXPERIMENT 2: High Imbalance (1:100) | Credit Card\n",
            "====================================================================================================\n",
            "\n",
            " Creating 1:100 imbalanced dataset...\n",
            "\n",
            "Created dataset with ratio 1:100.00\n",
            "Minority class: 147 samples\n",
            "Majority class: 14700 samples\n",
            "Total samples: 14847\n",
            "\n",
            "Train set: (10392, 30)\n",
            "Test set: (4455, 30)\n",
            "Train class distribution: [10289   103]\n",
            "Test class distribution: [4411   44]\n",
            "\n",
            "====================================================================================================\n",
            "ðŸ”¬ VARIATION 1/5: Conservative-Simple\n",
            "====================================================================================================\n",
            "Parameters: SMOTE_k=3, ADASYN_k=3, CTGAN_epochs=100\n",
            "\n",
            "[1/4] Running BASELINE...\n",
            "\n",
            "[2/4] Running SMOTE...\n",
            "SMOTE generated: 20578 samples (k_neighbors=3)\n",
            "\n",
            "[3/4] Running ADASYN...\n",
            "ADASYN generated: 20577 samples (n_neighbors=3)\n",
            "\n",
            "[4/4] Running CTGAN...\n",
            "CTGAN generated: 20578 samples\n",
            "\n",
            " Variation 1 Results:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "          model  precision   recall       f1  auc_roc technique  variation\n",
            "Baseline-LogReg   0.973684 0.840909 0.902439 0.997841  Baseline          1\n",
            "    Baseline-RF   1.000000 0.818182 0.900000 0.990316  Baseline          1\n",
            "   SMOTE-LogReg   0.245509 0.931818 0.388626 0.996398     SMOTE          1\n",
            "       SMOTE-RF   0.928571 0.886364 0.906977 0.998295     SMOTE          1\n",
            "  ADASYN-LogReg   0.086000 0.977273 0.158088 0.990937    ADASYN          1\n",
            "      ADASYN-RF   0.261905 1.000000 0.415094 0.997954    ADASYN          1\n",
            "   CTGAN-LogReg   1.000000 0.840909 0.913580 0.998202     CTGAN          1\n",
            "       CTGAN-RF   1.000000 0.840909 0.913580 0.976497     CTGAN          1\n",
            "\n",
            "====================================================================================================\n",
            "ðŸ”¬ VARIATION 2/5: Moderate-Balanced\n",
            "====================================================================================================\n",
            "Parameters: SMOTE_k=5, ADASYN_k=5, CTGAN_epochs=150\n",
            "\n",
            "[1/4] Running BASELINE...\n",
            "\n",
            "[2/4] Running SMOTE...\n",
            "SMOTE generated: 20578 samples (k_neighbors=5)\n",
            "\n",
            "[3/4] Running ADASYN...\n",
            "ADASYN generated: 20575 samples (n_neighbors=5)\n",
            "\n",
            "[4/4] Running CTGAN...\n",
            "CTGAN generated: 20578 samples\n",
            "\n",
            " Variation 2 Results:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "           model  precision   recall       f1  auc_roc technique  variation\n",
            " Baseline-LogReg   0.973684 0.840909 0.902439 0.997970  Baseline          2\n",
            "Baseline-XGBoost   1.000000 0.818182 0.900000 0.963361  Baseline          2\n",
            "    SMOTE-LogReg   0.241176 0.931818 0.383178 0.996584     SMOTE          2\n",
            "   SMOTE-XGBoost   0.863636 0.863636 0.863636 0.985821     SMOTE          2\n",
            "   ADASYN-LogReg   0.084848 0.954545 0.155844 0.991473    ADASYN          2\n",
            "  ADASYN-XGBoost   0.775510 0.863636 0.817204 0.994301    ADASYN          2\n",
            "    CTGAN-LogReg   1.000000 0.840909 0.913580 0.997656     CTGAN          2\n",
            "   CTGAN-XGBoost   0.972222 0.795455 0.875000 0.988958     CTGAN          2\n",
            "\n",
            "====================================================================================================\n",
            "ðŸ”¬ VARIATION 3/5: Aggressive-Complex\n",
            "====================================================================================================\n",
            "Parameters: SMOTE_k=7, ADASYN_k=7, CTGAN_epochs=200\n",
            "\n",
            "[1/4] Running BASELINE...\n",
            "\n",
            "[2/4] Running SMOTE...\n",
            "SMOTE generated: 20578 samples (k_neighbors=7)\n",
            "\n",
            "[3/4] Running ADASYN...\n",
            "ADASYN generated: 20581 samples (n_neighbors=7)\n",
            "\n",
            "[4/4] Running CTGAN...\n",
            "CTGAN generated: 20578 samples\n",
            "\n",
            " Variation 3 Results:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "           model  precision   recall       f1  auc_roc technique  variation\n",
            "     Baseline-RF   1.000000 0.840909 0.913580 0.993843  Baseline          3\n",
            "Baseline-XGBoost   1.000000 0.818182 0.900000 0.965108  Baseline          3\n",
            "        SMOTE-RF   1.000000 0.886364 0.939759 0.994945     SMOTE          3\n",
            "   SMOTE-XGBoost   0.975000 0.886364 0.928571 0.992544     SMOTE          3\n",
            "       ADASYN-RF   0.672414 0.886364 0.764706 0.996208    ADASYN          3\n",
            "  ADASYN-XGBoost   0.951220 0.886364 0.917647 0.995260    ADASYN          3\n",
            "        CTGAN-RF   0.880952 0.840909 0.860465 0.992823     CTGAN          3\n",
            "   CTGAN-XGBoost   0.925000 0.840909 0.880952 0.988778     CTGAN          3\n",
            "\n",
            "====================================================================================================\n",
            "ðŸ”¬ VARIATION 4/5: HighK-Deep\n",
            "====================================================================================================\n",
            "Parameters: SMOTE_k=10, ADASYN_k=10, CTGAN_epochs=250\n",
            "\n",
            "[1/4] Running BASELINE...\n",
            "\n",
            "[2/4] Running SMOTE...\n",
            "SMOTE generated: 20578 samples (k_neighbors=10)\n",
            "\n",
            "[3/4] Running ADASYN...\n",
            "ADASYN generated: 20581 samples (n_neighbors=10)\n",
            "\n",
            "[4/4] Running CTGAN...\n",
            "CTGAN generated: 20578 samples\n",
            "\n",
            " Variation 4 Results:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "           model  precision   recall       f1  auc_roc technique  variation\n",
            "     Baseline-RF   1.000000 0.840909 0.913580 0.976781  Baseline          4\n",
            "Baseline-XGBoost   1.000000 0.840909 0.913580 0.982683  Baseline          4\n",
            "        SMOTE-RF   0.951220 0.886364 0.917647 0.997468     SMOTE          4\n",
            "   SMOTE-XGBoost   0.904762 0.863636 0.883721 0.993797     SMOTE          4\n",
            "       ADASYN-RF   0.866667 0.886364 0.876404 0.997568    ADASYN          4\n",
            "  ADASYN-XGBoost   0.829787 0.886364 0.857143 0.994260    ADASYN          4\n",
            "        CTGAN-RF   1.000000 0.840909 0.913580 0.989855     CTGAN          4\n",
            "   CTGAN-XGBoost   0.902439 0.840909 0.870588 0.990891     CTGAN          4\n",
            "\n",
            "====================================================================================================\n",
            "ðŸ”¬ VARIATION 5/5: Mixed-Regularized\n",
            "====================================================================================================\n",
            "Parameters: SMOTE_k=5, ADASYN_k=8, CTGAN_epochs=300\n",
            "\n",
            "[1/4] Running BASELINE...\n",
            "\n",
            "[2/4] Running SMOTE...\n",
            "SMOTE generated: 20578 samples (k_neighbors=5)\n",
            "\n",
            "[3/4] Running ADASYN...\n",
            "ADASYN generated: 20575 samples (n_neighbors=8)\n",
            "\n",
            "[4/4] Running CTGAN...\n",
            "CTGAN generated: 20578 samples\n",
            "\n",
            " Variation 5 Results:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "          model  precision   recall       f1  auc_roc technique  variation\n",
            "Baseline-LogReg   1.000000 0.840909 0.913580 0.998192  Baseline          5\n",
            "    Baseline-RF   1.000000 0.818182 0.900000 0.993596  Baseline          5\n",
            "   SMOTE-LogReg   0.262500 0.954545 0.411765 0.997161     SMOTE          5\n",
            "       SMOTE-RF   1.000000 0.886364 0.939759 0.997135     SMOTE          5\n",
            "  ADASYN-LogReg   0.086777 0.954545 0.159091 0.994384    ADASYN          5\n",
            "      ADASYN-RF   0.500000 0.931818 0.650794 0.997053    ADASYN          5\n",
            "   CTGAN-LogReg   1.000000 0.840909 0.913580 0.998331     CTGAN          5\n",
            "       CTGAN-RF   0.973684 0.840909 0.902439 0.992684     CTGAN          5\n",
            "\n",
            "====================================================================================================\n",
            " EXPERIMENT 2: High Imbalance (1:100) - Credit Card - SUMMARY\n",
            "====================================================================================================\n",
            "          precision              recall                  f1            \\\n",
            "               mean       std      mean       std      mean       std   \n",
            "technique                                                               \n",
            "ADASYN     0.511513  0.353129  0.922727  0.046945  0.577202  0.322535   \n",
            "Baseline   0.994737  0.011096  0.831818  0.011736  0.905920  0.006659   \n",
            "CTGAN      0.965430  0.045739  0.836364  0.014374  0.895735  0.021505   \n",
            "SMOTE      0.737237  0.339003  0.897727  0.030773  0.756364  0.250908   \n",
            "\n",
            "            auc_roc            \n",
            "               mean       std  \n",
            "technique                      \n",
            "ADASYN     0.994940  0.002390  \n",
            "Baseline   0.985969  0.013395  \n",
            "CTGAN      0.991467  0.006452  \n",
            "SMOTE      0.995015  0.003687  \n",
            "\n",
            "âœ“ Results saved to 'credit_card_exp2_1to100.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8. Comprehensive Analysis - Both datasets**"
      ],
      "metadata": {
        "id": "CzqVFTUqh4rV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all results from both datasets\n",
        "results_breast_exp1['experiment'] = '1:10'\n",
        "results_breast_exp2['experiment'] = '1:100'\n",
        "\n",
        "results_credit_exp1['experiment'] = '1:10'\n",
        "results_credit_exp2['experiment'] = '1:100'\n",
        "\n",
        "all_results = pd.concat([\n",
        "    results_breast_exp1, results_breast_exp2,\n",
        "    results_credit_exp1, results_credit_exp2\n",
        "], ignore_index=True)\n",
        "\n",
        "all_results.to_csv('ALL_EXPERIMENTS_COMBINED.csv', index=False)\n",
        "\n",
        "\n",
        "print(\" ALL RESULTS COMBINED\")\n",
        "print(\"=\"*100)\n",
        "print(f\"\\n All results saved to 'ALL_EXPERIMENTS_COMBINED.csv'\")\n",
        "print(f\"\\nTotal experiments run: {len(all_results)}\")\n",
        "print(f\"\\nBreakdown:\")\n",
        "print(f\"  Breast Cancer experiments: {len(results_breast_exp1) + len(results_breast_exp2)}\")\n",
        "print(f\"  Credit Card experiments: {len(results_credit_exp1) + len(results_credit_exp2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oe0UQTRJiCSz",
        "outputId": "055b5907-0319-4d57-a3ce-977bc44abaed"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " ALL RESULTS COMBINED\n",
            "====================================================================================================\n",
            "\n",
            " All results saved to 'ALL_EXPERIMENTS_COMBINED.csv'\n",
            "\n",
            "Total experiments run: 160\n",
            "\n",
            "Breakdown:\n",
            "  Breast Cancer experiments: 80\n",
            "  Credit Card experiments: 80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Statistical Summary by Dataset and Technique\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\" OVERALL STATISTICAL SUMMARY - BY DATASET AND TECHNIQUE\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "summary_by_dataset_technique = all_results.groupby(['dataset', 'experiment', 'technique']).agg({\n",
        "    'precision': ['mean', 'std'],\n",
        "    'recall': ['mean', 'std'],\n",
        "    'f1': ['mean', 'std'],\n",
        "    'auc_roc': ['mean', 'std']\n",
        "}).round(4)\n",
        "\n",
        "print(summary_by_dataset_technique)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JO1QaWoWitjB",
        "outputId": "c5c7fa71-ff83-41a7-924a-2a9548f020bc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            " OVERALL STATISTICAL SUMMARY - BY DATASET AND TECHNIQUE\n",
            "====================================================================================================\n",
            "                                   precision          recall              f1  \\\n",
            "                                        mean     std    mean     std    mean   \n",
            "dataset       experiment technique                                             \n",
            "Breast Cancer 1:10       ADASYN       0.4825  0.1548  0.6345  0.0884  0.5222   \n",
            "                         Baseline     0.7719  0.0654  0.4236  0.1007  0.5357   \n",
            "                         CTGAN        0.7809  0.0639  0.4273  0.1040  0.5407   \n",
            "                         SMOTE        0.4796  0.1396  0.6327  0.0746  0.5251   \n",
            "              1:100      ADASYN       0.3560  0.3714  0.5109  0.1520  0.2843   \n",
            "                         Baseline     0.9699  0.0484  0.1818  0.1121  0.2903   \n",
            "                         CTGAN        0.8718  0.3095  0.1764  0.1314  0.2772   \n",
            "                         SMOTE        0.3628  0.3900  0.5073  0.1481  0.2803   \n",
            "Credit Card   1:10       ADASYN       0.7854  0.1267  0.9023  0.0216  0.8336   \n",
            "                         Baseline     0.9924  0.0169  0.8295  0.0221  0.9034   \n",
            "                         CTGAN        0.9725  0.0273  0.8591  0.0179  0.9120   \n",
            "                         SMOTE        0.8910  0.0673  0.8795  0.0216  0.8837   \n",
            "              1:100      ADASYN       0.5115  0.3531  0.9227  0.0469  0.5772   \n",
            "                         Baseline     0.9947  0.0111  0.8318  0.0117  0.9059   \n",
            "                         CTGAN        0.9654  0.0457  0.8364  0.0144  0.8957   \n",
            "                         SMOTE        0.7372  0.3390  0.8977  0.0308  0.7564   \n",
            "\n",
            "                                           auc_roc          \n",
            "                                       std    mean     std  \n",
            "dataset       experiment technique                          \n",
            "Breast Cancer 1:10       ADASYN     0.0927  0.8708  0.0083  \n",
            "                         Baseline   0.0843  0.8644  0.0056  \n",
            "                         CTGAN      0.0852  0.8638  0.0063  \n",
            "                         SMOTE      0.0800  0.8700  0.0088  \n",
            "              1:100      ADASYN     0.2036  0.8444  0.0277  \n",
            "                         Baseline   0.1525  0.8541  0.0262  \n",
            "                         CTGAN      0.1796  0.8520  0.0232  \n",
            "                         SMOTE      0.1956  0.8451  0.0263  \n",
            "Credit Card   1:10       ADASYN     0.0706  0.9611  0.0040  \n",
            "                         Baseline   0.0089  0.9567  0.0039  \n",
            "                         CTGAN      0.0147  0.9524  0.0047  \n",
            "                         SMOTE      0.0321  0.9578  0.0068  \n",
            "              1:100      ADASYN     0.3225  0.9949  0.0024  \n",
            "                         Baseline   0.0067  0.9860  0.0134  \n",
            "                         CTGAN      0.0215  0.9915  0.0065  \n",
            "                         SMOTE      0.2509  0.9950  0.0037  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Best performers for each dataset and experiment\n",
        "print(\"\\n\" + \"=\"*100)\n",
        "print(\" BEST PERFORMING TECHNIQUES (by F1-Score)\")\n",
        "print(\"=\"*100)\n",
        "\n",
        "for dataset in ['Breast Cancer', 'Credit Card']:\n",
        "    print(f\"\\n{'='*100}\")\n",
        "    print(f\" {dataset.upper()}\")\n",
        "    print(f\"{'='*100}\")\n",
        "\n",
        "    dataset_results = all_results[all_results['dataset'] == dataset]\n",
        "\n",
        "    for exp in ['1:10', '1:100', '1:1000']:\n",
        "        exp_data = dataset_results[dataset_results['experiment'] == exp]\n",
        "        if len(exp_data) > 0:\n",
        "            best_idx = exp_data['f1'].idxmax()\n",
        "            best_row = exp_data.loc[best_idx]\n",
        "            print(f\"\\n  {exp}:\")\n",
        "            print(f\"    Best: {best_row['technique']} - {best_row['model']}\")\n",
        "            print(f\"    F1: {best_row['f1']:.4f} | Recall: {best_row['recall']:.4f} | AUC-ROC: {best_row['auc_roc']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzFZEm1ni3aI",
        "outputId": "660e3805-335f-4381-f08c-b7d7ff7bad2d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====================================================================================================\n",
            " BEST PERFORMING TECHNIQUES (by F1-Score)\n",
            "====================================================================================================\n",
            "\n",
            "====================================================================================================\n",
            " BREAST CANCER\n",
            "====================================================================================================\n",
            "\n",
            "  1:10:\n",
            "    Best: CTGAN - CTGAN-XGBoost\n",
            "    F1: 0.6458 | Recall: 0.5636 | AUC-ROC: 0.8745\n",
            "\n",
            "  1:100:\n",
            "    Best: ADASYN - ADASYN-XGBoost\n",
            "    F1: 0.5750 | Recall: 0.4182 | AUC-ROC: 0.8622\n",
            "\n",
            "====================================================================================================\n",
            " CREDIT CARD\n",
            "====================================================================================================\n",
            "\n",
            "  1:10:\n",
            "    Best: CTGAN - CTGAN-LogReg\n",
            "    F1: 0.9286 | Recall: 0.8864 | AUC-ROC: 0.9575\n",
            "\n",
            "  1:100:\n",
            "    Best: SMOTE - SMOTE-RF\n",
            "    F1: 0.9398 | Recall: 0.8864 | AUC-ROC: 0.9949\n"
          ]
        }
      ]
    }
  ]
}